{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import arcpy\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from skimage.transform import resize\n",
    "\n",
    "arcpy.env.parallelProcessingFactor = \"50%\"\n",
    "arcpy.env.pyramid = \"NONE\"\n",
    "arcpy.env.rasterStatistics = 'NONE'\n",
    "arcpy.SetLogMetadata(False)\n",
    "arcpy.SetLogHistory(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Verification that GPU is active.\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArcGIS variables\n",
    "path = \"H:/Python/arcpy_tensorflow/\"\n",
    "path_raster = \"R:/SIGR/DonneesCommunes/FONDS/ORTHOPHOTO/ortho2021.gdb/orthophoto2021\"\n",
    "raster = arcpy.Raster(path_raster)\n",
    "img_size = 250 # Size of the images you want to crop\n",
    "resolution = 0.15 # Resolution of your raster in meters\n",
    "\n",
    "# Model variables\n",
    "width, height = 250, 250 # size of the images in the dataset\n",
    "batch_size = 8\n",
    "epochs = 10 # Number of epoch for training\n",
    "name_model = 'Raster-Chantier-inator.h5' # The name of the model, it will save the weights of the model as a .h5 file if you want to use the inference later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(array):\n",
    "    array = array.T\n",
    "    array = np.rot90(array,k=-1)\n",
    "    array = np.flip(array,axis=1)\n",
    "    array = resize(array,(width,height)) # resizing for the model\n",
    "    return array\n",
    "\n",
    "def load_image(Coordx,Coordy,img_size=img_size,raster=raster):\n",
    "    array = arcpy.RasterToNumPyArray(raster,arcpy.Point(Coordx,Coordy),img_size,img_size)\n",
    "    array = processing(array)\n",
    "    return array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a data generator using arcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, data_file, batch_size):\n",
    "        self.data_file = data_file\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = self.get_num_samples()\n",
    "        self.num_batches = int(np.ceil(self.num_samples / self.batch_size))\n",
    "\n",
    "    def get_num_samples(self):\n",
    "        # Implement your logic to determine the total number of samples\n",
    "        # in your dataset file and return that value.\n",
    "        # For example, if your data file is a CSV file, you can use pandas\n",
    "        # to read the file and count the number of rows.\n",
    "        # return num_samples\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_index = index * self.batch_size\n",
    "        end_index = min(start_index + self.batch_size, self.num_samples)\n",
    "\n",
    "        batch_x, batch_y = self.load_data_chunk(start_index, end_index)\n",
    "\n",
    "        # Preprocess your data if needed\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def load_data_chunk(self, start_index, end_index):\n",
    "        # Implement your logic to load a chunk of data from the file\n",
    "        # based on the given start and end indexes.\n",
    "        # For example, if your data file is a CSV file, you can use pandas\n",
    "        # to read the specific rows within the range and extract the\n",
    "        # features and labels.\n",
    "        # return batch_x, batch_y\n",
    "        pass\n",
    "# Example usage\n",
    "data_file = 'path/to/your/data/file.csv'  # Replace with your data file path\n",
    "train_data_generator = DataGenerator(data_file, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = train_ds.class_names\n",
    "# print(class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "def time_it(func):\n",
    "    \"\"\"\n",
    "    Usage : Put @time_it before your function to calculate execution time.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"Execution time of {func.__name__}: {end - start:.5f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of some images to check that everything is going smoothly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(min(9,batch_size)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds: # Printing the shape of the dataset\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "Here is a list of available model to use as a backbone : https://keras.io/api/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "# Backbone of the model\n",
    "base_model = tf.keras.applications.EfficientNetB3(input_shape=(height, width,3), include_top=False ,weights='imagenet')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = base_model.output # derni√®re couche\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(last)\n",
    "# Fully connected layer\n",
    "x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "# Logistic layer (number of classes)\n",
    "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "model1 = tf.keras.Model(base_model.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='auto', verbose=0,patience=30)\n",
    "mc = ModelCheckpoint(name_model, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional ResNet152V2 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model1.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only train top layers\n",
    "with tf.device('/device:GPU:0'): # ensure that training is done by GPU just in case\n",
    "    history = model1.fit(train_ds, validation_data=val_ds,batch_size=batch_size, epochs=epochs,verbose=1, callbacks = [es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "print(len(model1.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model1.layers:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "model1.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history11 = model1.fit(train_ds, validation_data=val_ds,batch_size=batch_size, epochs=epochs,verbose=1, callbacks = [es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_dir_test != None:\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            data_dir_test,\n",
    "            seed=123,\n",
    "            image_size=(height, width),\n",
    "            batch_size=batch_size)\n",
    "    model1.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
